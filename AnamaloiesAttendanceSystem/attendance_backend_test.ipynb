{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8bb1342",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d981e02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.vscode',\n",
       " 'attendance_backend_test.ipynb',\n",
       " 'Images',\n",
       " 'Output_Reports',\n",
       " \"PDF's\"]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00bea1f5",
   "metadata": {},
   "source": [
    "### PDF TO IMAGE CONVERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83efcb37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully converted 1 pages from PDF's/AOA VKC.pdf to images.\n"
     ]
    }
   ],
   "source": [
    "from pdf2image import convert_from_path\n",
    "\n",
    "# 1. Update this path to the actual 'bin' folder in your Poppler download\n",
    "# Example: If you unzipped it to C:\\Program Files\\poppler-23.01.0\\\n",
    "poppler_path = r\"C:\\Users\\Jash\\AppData\\Local\\Programs\\poppler-25.07.0\\Library\\bin\" \n",
    "\n",
    "pdf_path = \"PDF's/AOA VKC.pdf\"\n",
    "\n",
    "try:\n",
    "    # Pass the poppler_path argument to convert_from_path\n",
    "    images = convert_from_path(pdf_path, poppler_path=poppler_path)\n",
    "\n",
    "    for i, image in enumerate(images):\n",
    "        image.save(f'Images/page_{i+1}.jpg', 'JPEG')\n",
    "\n",
    "    print(f\"Successfully converted {len(images)} pages from {pdf_path} to images.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "    print(\"Please ensure the poppler_path is correct.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d8d202",
   "metadata": {},
   "source": [
    "### OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80016d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7764250",
   "metadata": {},
   "outputs": [],
   "source": [
    "pytesseract.pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3373f2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open('Images/page_1.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b53b282",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "332f1890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PARSHVANATH'S CHARITABLE TRUST'S\n",
      "\n",
      "A. P, SHAH INSTITUTE OF TECHNOLOGY\n",
      "STUDENT ATTENDANCE REPORT (ep\n",
      "DEPARTMENT OF COMPUTER ENGINEERING. N97]\n",
      "\n",
      "Academic Year 2025-29 26\n",
      "ub: OF\n",
      "\n",
      "a a\n",
      "a Aether eerie} | le rob \\\\otad i fert 24 \\7 Jes\n",
      "\n",
      "[me | | yee |' aso! ipa | Lo)\n",
      "LNO | STUDENTID STUDENT NAME “ —— ol gom a\n",
      "Saeco — 8p] ote ZN| xX | s=— ———\n",
      "| Ss fesse —|-—]* ate idee es” ~~ | 7s ce Pi\n",
      "J tea rasone arama —| | PT RSS8| RNS] Rg | hans | NERS Gos = — | pa NSH! pS\n",
      "s[e | 2e0s1 [BRANDARTRASATONESH [| Poel 6A eat ee Ce eth le ete nude\n",
      "c{-.81iof amiss [SIGGARANORAGMARADEO | ee + | ae é ue:\n",
      "\n",
      "ie]\n",
      "Ht\n",
      "\n",
      "J\n",
      "\n",
      "i]\n",
      "\n",
      "[82 | _ 24102200 _ |BONGULWAR POOIA MAKARAND\n",
      "eres | esteaie _| BOPALKAR JATIN JITENDRA\n",
      "sare\n",
      "| 86 | 2aioz0s1_ | i ee\n",
      "|__88 | 24102017 _ [DESHPANDE TANISHQ SACHIN pes i. Ca\n",
      "aie B Ae\n",
      "be — ee ees\n",
      "\n",
      "| 89 | 24102201 _|DIGASKAR TEJAS SANTOSH\n",
      "[90 | 24102107 [DORLEHARSHSANTOSH |_} 7 ye\n",
      "\n",
      "2 poe ST VOEANSIE NOS OSE AS tem\n",
      "\n",
      "i | + | —_\n",
      "\n",
      "[a1 | 24102065 [DOSHI METI MAYUR\n",
      "|_92 | 24102043 [DUNGARWAL SIDDHI ASHISH\n",
      "| 97 |\n",
      "| 9s\n",
      "\n",
      "24102090 GANDHI PRANESH RIKESHKUMAR\n",
      "\n",
      "24102184 GAWALI SAMRUDDHI SATISH\n",
      "\n",
      "a UTKARSHA SANTOSH\n",
      "24102056 Pe PARAS AMOL\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e39716",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "703851ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('Images/page_1.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a3e41fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7bb60ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply binarization (e.g., black and white) to reduce complexity\n",
    "_, binary_image = cv2.threshold(gray, 128, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "566206fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Table and Text Extraction (Using a special Tesseract mode)\n",
    "# Use a Page Segmentation Mode (PSM) configured for a single block of text or a table\n",
    "custom_config = r'--oem 3 --psm 6' \n",
    "extracted_text = pytesseract.image_to_string(binary_image, config=custom_config) # Extracts text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "136b3b01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'el\\nnea :\\nz|* : A EERE LEE\\n> 5 z Ale :\\n\\nTL Tob\\nHIME il\\nSEKLAL\\nHae EATS raeP (EF a\\nPer ae i ss oe | fed\\naa Yi LN ae Me 18] Gi\\nna Da alle\\neg | CELE ae : At\\n\\nREA *\\n\\nSIS)\\n'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9ea3e723",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(img_path):\n",
    "    \"\"\"Loads image, converts to grayscale, and applies thresholding.\"\"\"\n",
    "    # Read the image\n",
    "    img = cv2.imread(img_path)\n",
    "    \n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply thresholding (e.g., adaptive thresholding for varied lighting)\n",
    "    # This separates the text/lines from the background\n",
    "    binary_img = cv2.adaptiveThreshold(\n",
    "        gray, 255, \n",
    "        cv2.ADAPTIVE_THRESH_GAUSSIAN_C, \n",
    "        cv2.THRESH_BINARY_INV, 11, 2\n",
    "    )\n",
    "    \n",
    "    # Use morphological operations (dilation/erosion) to thicken lines/close gaps\n",
    "    kernel = np.ones((2, 2), np.uint8) # Small kernel to close minor breaks\n",
    "    dilated_img = cv2.dilate(binary_img, kernel, iterations=1)\n",
    "    \n",
    "    return img, dilated_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "44347437",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_table_data(processed_img):\n",
    "    \"\"\"\n",
    "    Uses pytesseract's detailed output (image_to_data) to get coordinates \n",
    "    and text, then structures it into a DataFrame.\n",
    "    \"\"\"\n",
    "    # Use a configuration optimized for a sparse table (PSM 6: Assume a single uniform block of text)\n",
    "    config = r'--oem 3 --psm 6'\n",
    "\n",
    "    # Get verbose data, including bounding box coordinates for every detected word/character\n",
    "    data = pytesseract.image_to_data(processed_img, output_type=pytesseract.Output.DATAFRAME, config=config)\n",
    "    \n",
    "    # Filter out empty or low-confidence lines\n",
    "    data = data.dropna(subset=['text'])\n",
    "    data = data[data.conf > 30] \n",
    "    \n",
    "    if data.empty:\n",
    "        print(\"Error: No text extracted. Check image quality and Tesseract path.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # --- Reconstruction Logic (Highly simplified and relies on sorting coordinates) ---\n",
    "    \n",
    "    # Sort by 'top' (Y-coordinate) to group words into rows\n",
    "    # Then sort by 'left' (X-coordinate) within each row\n",
    "    data = data.sort_values(by=['top', 'left'])\n",
    "\n",
    "    # Conceptual approach: Group data into virtual cells based on Y-coordinates\n",
    "    # In a full solution, you would cluster X-coordinates to determine column boundaries.\n",
    "    \n",
    "    # For simplicity, we'll try to use the raw text output structured by Tesseract (tesseract HOCR format)\n",
    "    # The image_to_data output is better for complex tables:\n",
    "    \n",
    "    # To reconstruct the grid, you need to define column boundaries.\n",
    "    # For a dense table like yours, a common approach is to:\n",
    "    # 1. Identify all unique X-coordinates (or clusters of X-coordinates) to define vertical column lines.\n",
    "    # 2. Iterate through the data, placing each 'text' into the correct column based on its 'left' coordinate.\n",
    "    \n",
    "    # Simplified structure attempt (may result in merged cells/bad alignment):\n",
    "    # This uses Tesseract's natural grouping into lines (level 4)\n",
    "    df_raw = data.query('level == 4').groupby('block_num')['text'].apply(lambda x: ' '.join(x)).reset_index()\n",
    "\n",
    "    # Further complex processing is needed here to split 'text' by columns.\n",
    "    # Because this requires advanced clustering (Computer Vision + Data Science), \n",
    "    # we'll return a simple but potentially messy DataFrame.\n",
    "    \n",
    "    return data # Returning the raw data with coordinates for debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ec447c5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SUCCESS: Raw OCR data with coordinates saved to Output_Reports/Raw_OCR_Data.xlsx\n",
      "Note: This output needs manual processing to form a clean table.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    IMAGE_PATH = 'Images/page_1.jpg'\n",
    "    OUTPUT_EXCEL = 'Output_Reports/Raw_OCR_Data.xlsx'\n",
    "    \n",
    "    img_color, img_processed = preprocess_image(IMAGE_PATH)\n",
    "    raw_data_df = extract_table_data(img_processed)\n",
    "    \n",
    "    if not raw_data_df.empty:\n",
    "        \n",
    "        # --- Custom Table Reconstruction Placeholder ---\n",
    "        # The reconstruction code is too complex for a template and is HIGHLY dependent on the image.\n",
    "        # Libraries like img2table (Option 1) handle this complex reconstruction internally.\n",
    "        \n",
    "        # For this template, we export the raw coordinate data for analysis\n",
    "        output_df = raw_data_df[['left', 'top', 'text', 'conf']].copy()\n",
    "        \n",
    "        # In a real solution, you would convert this into a clean N x M table (M rows, N columns)\n",
    "        # Final_Attendance_DF = reconstruct_grid(raw_data_df)\n",
    "        \n",
    "        # Export the coordinate data to Excel\n",
    "        output_df.to_excel(OUTPUT_EXCEL, index=False)\n",
    "        print(f\"\\nSUCCESS: Raw OCR data with coordinates saved to {OUTPUT_EXCEL}\")\n",
    "        print(\"Note: This output needs manual processing to form a clean table.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fefd128",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# --- Configuration ---\n",
    "# 1. Update this path to your Tesseract executable (MANDATORY on Windows)\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe' \n",
    "\n",
    "# 2. Input/Output Files\n",
    "IMAGE_PATH = 'page_1.jpg'\n",
    "OUTPUT_EXCEL = 'attendance_grid_output.xlsx'\n",
    "\n",
    "# --- 1. Image Processing: Detect Grid Lines ---\n",
    "\n",
    "def detect_and_clean_grid(img_path):\n",
    "    \"\"\"Detects and isolates the horizontal and vertical lines in the image.\"\"\"\n",
    "    img = cv2.imread(img_path)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # 1. Thresholding to create a binary image\n",
    "    _, binary_img = cv2.threshold(gray, 180, 255, cv2.THRESH_BINARY_INV) # Threshold may need tuning\n",
    "    \n",
    "    # 2. Define Kernels for morphological operations\n",
    "    # Horizontal kernel (wide and short) to detect horizontal lines\n",
    "    kernel_h = cv2.getStructuringElement(cv2.MORPH_RECT, (40, 1)) \n",
    "    # Vertical kernel (tall and thin) to detect vertical lines\n",
    "    kernel_v = cv2.getStructuringElement(cv2.MORPH_RECT, (1, 40)) \n",
    "\n",
    "    # 3. Apply Morphological Operations\n",
    "    \n",
    "    # Isolate horizontal lines\n",
    "    horz_lines = cv2.erode(binary_img, kernel_h, iterations=1)\n",
    "    horz_lines = cv2.dilate(horz_lines, kernel_h, iterations=1)\n",
    "    \n",
    "    # Isolate vertical lines\n",
    "    vert_lines = cv2.erode(binary_img, kernel_v, iterations=1)\n",
    "    vert_lines = cv2.dilate(vert_lines, kernel_v, iterations=1)\n",
    "    \n",
    "    # 4. Combine the lines\n",
    "    full_grid = cv2.add(horz_lines, vert_lines)\n",
    "    \n",
    "    # 5. Find contours of the full grid (these define the cells)\n",
    "    contours, _ = cv2.findContours(full_grid, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    return img, contours, horz_lines, vert_lines # Returning lines for later use\n",
    "\n",
    "# --- 2. Table Reconstruction (Complex: Requires Mapping Lines to Text) ---\n",
    "\n",
    "def reconstruct_table(img, contours, vert_lines, horz_lines):\n",
    "    \"\"\"\n",
    "    Conceptual function to map OCR text back into the grid defined by lines.\n",
    "    THIS PART IS HIGHLY COMPLEX and usually requires iterative fine-tuning.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Find the average X and Y positions of lines to define true column/row splits\n",
    "    \n",
    "    # --- Step A: Define Column (X) and Row (Y) Boundaries ---\n",
    "    \n",
    "    # 1. Detect X-coordinates of vertical lines to define columns\n",
    "    vert_projection = np.sum(vert_lines, axis=0) # Sum pixel values vertically\n",
    "    # Find peaks in the projection to get column separation points\n",
    "    # (Requires sophisticated peak detection/clustering)\n",
    "    \n",
    "    # 2. Detect Y-coordinates of horizontal lines to define rows\n",
    "    horz_projection = np.sum(horz_lines, axis=1) # Sum pixel values horizontally\n",
    "    # Find peaks in the projection to get row separation points\n",
    "    \n",
    "    # --- Step B: Iterate and OCR Each Cell ---\n",
    "    \n",
    "    final_table = []\n",
    "    \n",
    "    # This loop is conceptual, as getting the *exact* coordinates for cropping is the challenge\n",
    "    for r_start, r_end in (conceptual_row_boundaries):\n",
    "        row_data = []\n",
    "        for c_start, c_end in (conceptual_column_boundaries):\n",
    "            \n",
    "            # 1. Crop the cell area from the original image\n",
    "            cell_img = img[r_start:r_end, c_start:c_end]\n",
    "            \n",
    "            # 2. OCR the cropped cell\n",
    "            # Use PSM 10 (Single Character) or PSM 8 (Single Word) for attendance marks\n",
    "            cell_text = pytesseract.image_to_string(cell_img, config='--psm 10').strip()\n",
    "            \n",
    "            # 3. Apply your custom cleaning/mapping function (P/A/Dot -> Present/Absent/Unclear)\n",
    "            # cell_text = clean_attendance_marks(cell_text) # Your previous function\n",
    "            \n",
    "            row_data.append(cell_text)\n",
    "        final_table.append(row_data)\n",
    "\n",
    "    # Convert the final list of lists into a Pandas DataFrame\n",
    "    df = pd.DataFrame(final_table)\n",
    "    return df\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "# --- 3. Main Execution and Export ---\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    try:\n",
    "        img_color, cell_contours, horz_lines, vert_lines = detect_and_clean_grid(IMAGE_PATH)\n",
    "        \n",
    "        # Display the detected lines (Optional, for debugging)\n",
    "        # cv2.imwrite('detected_grid.jpg', cv2.add(horz_lines, vert_lines))\n",
    "        # print(\"Saved 'detected_grid.jpg' for visual debugging.\")\n",
    "        \n",
    "        final_df = reconstruct_table(img_color, cell_contours, vert_lines, horz_lines)\n",
    "\n",
    "        # if not final_df.empty:\n",
    "        #     final_df.to_excel(OUTPUT_EXCEL, index=False)\n",
    "        #     print(f\"\\nSUCCESS: Data saved to {OUTPUT_EXCEL}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\nAn error occurred during execution: {e}\")\n",
    "        print(\"Ensure Tesseract and all libraries are installed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f3821362",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- 1. Image Processing ---\n",
    "\n",
    "def deskew_and_preprocess(img_path):\n",
    "    \"\"\"\n",
    "    Attempts to detect and correct image skew using Tesseract OSD, \n",
    "    then converts to a binary image.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Open the image with PIL\n",
    "        img_pil = Image.open(img_path)\n",
    "        \n",
    "        # Get Orientation from Tesseract (PSM 0 is for OSD only)\n",
    "        osd_config = r'--psm 0'\n",
    "        osd_data = pytesseract.image_to_osd(img_pil, config=osd_config)\n",
    "        \n",
    "        # Simple parsing to get the angle\n",
    "        angle_match = next((line for line in osd_data.split('\\n') if line.startswith('Rotate:')), None)\n",
    "        rotation_angle = int(angle_match.split(': ')[1]) if angle_match else 0\n",
    "\n",
    "        print(f\"Detected rotation angle: {rotation_angle}°\")\n",
    "        \n",
    "        if rotation_angle != 0:\n",
    "            print(f\"Deskewing: Detected rotation angle: {rotation_angle}°\")\n",
    "            # Rotate and expand to ensure no content is clipped\n",
    "            rotated_img_pil = img_pil.rotate(rotation_angle, expand=True)\n",
    "        else:\n",
    "            rotated_img_pil = img_pil\n",
    "\n",
    "        # Convert PIL Image back to OpenCV format\n",
    "        img_np = np.array(rotated_img_pil.convert('RGB'))\n",
    "        img_color = cv2.cvtColor(img_np, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # Convert to grayscale and apply thresholding\n",
    "        gray = cv2.cvtColor(img_color, cv2.COLOR_BGR2GRAY)\n",
    "        # Use a high threshold for better contrast on marks, adjust 180 as needed\n",
    "        _, binary_img = cv2.threshold(gray, 180, 255, cv2.THRESH_BINARY)\n",
    "        \n",
    "        return binary_img\n",
    "\n",
    "    except pytesseract.TesseractNotFoundError:\n",
    "        print(\"Tesseract not found. Check tesseract_cmd path!\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error during deskewing/preprocessing: {e}\")\n",
    "        return None\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "59e8429d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_table_data(processed_img):\n",
    "    \"\"\"\n",
    "    Uses pytesseract's detailed output (image_to_data) to get coordinates \n",
    "    and text, then structures it into a DataFrame.\n",
    "    \"\"\"\n",
    "    # Use PSM 6: Assume a single uniform block of text.\n",
    "    config = r'--oem 3 --psm 6' \n",
    "\n",
    "    # Get verbose data: 'left', 'top', 'height', 'width', 'text', 'conf', etc.\n",
    "    data = pytesseract.image_to_data(processed_img, output_type=pytesseract.Output.DATAFRAME, config=config)\n",
    "    \n",
    "    # Filter out empty text and low-confidence results\n",
    "    data = data.dropna(subset=['text'])\n",
    "    data = data[data['text'].str.strip() != '']\n",
    "    data = data[data['conf'] > 30] \n",
    "    \n",
    "    if data.empty:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # --- Reconstruction Logic using Spatial Coordinates (top, left) ---\n",
    "    \n",
    "    # 1. Sort spatially\n",
    "    data = data.sort_values(by=['top', 'left'])\n",
    "\n",
    "    # 2. Custom Row Grouping (Tolerance for the same row)\n",
    "    row_tolerance = 20 # Adjust this value based on your cell height\n",
    "    data['row_id'] = (data['top'].diff() > row_tolerance).cumsum()\n",
    "\n",
    "    # 3. Custom Column Grouping (Clustering X-coordinates)\n",
    "    left_positions = data['left'].unique()\n",
    "    left_positions.sort()\n",
    "\n",
    "    column_clusters = []\n",
    "    current_cluster = []\n",
    "    \n",
    "    for x in left_positions:\n",
    "        if not current_cluster:\n",
    "            current_cluster.append(x)\n",
    "        elif x - current_cluster[-1] < 50: # Tolerance of 50 pixels for the same column\n",
    "            current_cluster.append(x)\n",
    "        else:\n",
    "            column_clusters.append(int(np.mean(current_cluster)))\n",
    "            current_cluster = [x]\n",
    "    if current_cluster:\n",
    "        column_clusters.append(int(np.mean(current_cluster)))\n",
    "\n",
    "    def get_column_id(left_coord):\n",
    "        return np.argmin(np.abs(np.array(column_clusters) - left_coord))\n",
    "\n",
    "    data['col_id'] = data['left'].apply(get_column_id)\n",
    "\n",
    "    # 4. Pivot the data to create the final DataFrame\n",
    "    # Note: Using max() or first() might merge words incorrectly; this is the biggest point of failure.\n",
    "    #final_df = data.pivot(index='row_id', columns='col_id', values='text').fillna('').apply(lambda x: ' '.join(x), axis=1)\n",
    "    \n",
    "    # After pivoting and joining, the column names are still messy numbers.\n",
    "    # We must manually clean the data.\n",
    "    \n",
    "    # Due to the complexity of the column structure in your image (Roll No, Name, then Dates),\n",
    "    # this resulting DataFrame requires one final cleanup pass.\n",
    "    \n",
    "    #return final_df.to_frame() # Return as a DataFrame\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c5624ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration ---\n",
    "# 1. Update this path to your Tesseract executable (MANDATORY on Windows)\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe' \n",
    "\n",
    "# 2. Input/Output Files\n",
    "IMAGE_PATH = 'Images/page_1.jpg'\n",
    "OUTPUT_EXCEL = 'attendance_grid_output.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a0f62f66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected rotation angle: 0°\n"
     ]
    }
   ],
   "source": [
    "img_processed = deskew_and_preprocess(IMAGE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "04626da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if img_processed is not None:\n",
    "    # Step 2: Extract Data and Structure\n",
    "    final_df = extract_table_data(img_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6fc126c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level</th>\n",
       "      <th>page_num</th>\n",
       "      <th>block_num</th>\n",
       "      <th>par_num</th>\n",
       "      <th>line_num</th>\n",
       "      <th>word_num</th>\n",
       "      <th>left</th>\n",
       "      <th>top</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>conf</th>\n",
       "      <th>text</th>\n",
       "      <th>row_id</th>\n",
       "      <th>col_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1400</td>\n",
       "      <td>344</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>41.559139</td>\n",
       "      <td>|</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>175</td>\n",
       "      <td>435</td>\n",
       "      <td>24</td>\n",
       "      <td>66</td>\n",
       "      <td>37.183258</td>\n",
       "      <td>el</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>215</td>\n",
       "      <td>435</td>\n",
       "      <td>28</td>\n",
       "      <td>66</td>\n",
       "      <td>52.886387</td>\n",
       "      <td>&amp;)</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>336</td>\n",
       "      <td>435</td>\n",
       "      <td>22</td>\n",
       "      <td>66</td>\n",
       "      <td>36.425919</td>\n",
       "      <td>S|</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>413</td>\n",
       "      <td>448</td>\n",
       "      <td>13</td>\n",
       "      <td>20</td>\n",
       "      <td>36.664349</td>\n",
       "      <td>§</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>164</td>\n",
       "      <td>783</td>\n",
       "      <td>500</td>\n",
       "      <td>112</td>\n",
       "      <td>36.809917</td>\n",
       "      <td>TTT</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1102</td>\n",
       "      <td>786</td>\n",
       "      <td>151</td>\n",
       "      <td>116</td>\n",
       "      <td>40.074837</td>\n",
       "      <td>eee</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1350</td>\n",
       "      <td>883</td>\n",
       "      <td>22</td>\n",
       "      <td>61</td>\n",
       "      <td>33.002319</td>\n",
       "      <td>PR</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>913</td>\n",
       "      <td>162</td>\n",
       "      <td>24</td>\n",
       "      <td>40.332829</td>\n",
       "      <td>AH</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>1287</td>\n",
       "      <td>1537</td>\n",
       "      <td>82</td>\n",
       "      <td>31</td>\n",
       "      <td>32.156410</td>\n",
       "      <td>Ga</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>1282</td>\n",
       "      <td>1546</td>\n",
       "      <td>94</td>\n",
       "      <td>77</td>\n",
       "      <td>78.016541</td>\n",
       "      <td>@</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>1041</td>\n",
       "      <td>1557</td>\n",
       "      <td>163</td>\n",
       "      <td>72</td>\n",
       "      <td>35.844048</td>\n",
       "      <td>We</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>932</td>\n",
       "      <td>1595</td>\n",
       "      <td>70</td>\n",
       "      <td>99</td>\n",
       "      <td>38.215660</td>\n",
       "      <td>Fe</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>1040</td>\n",
       "      <td>1601</td>\n",
       "      <td>32</td>\n",
       "      <td>71</td>\n",
       "      <td>53.231361</td>\n",
       "      <td>DAI</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>636</td>\n",
       "      <td>1618</td>\n",
       "      <td>146</td>\n",
       "      <td>86</td>\n",
       "      <td>49.561317</td>\n",
       "      <td>LEP</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>1180</td>\n",
       "      <td>1619</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>42.241776</td>\n",
       "      <td>|B</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>1005</td>\n",
       "      <td>1686</td>\n",
       "      <td>229</td>\n",
       "      <td>137</td>\n",
       "      <td>42.315910</td>\n",
       "      <td>ae</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>270</td>\n",
       "      <td>1765</td>\n",
       "      <td>120</td>\n",
       "      <td>120</td>\n",
       "      <td>36.928120</td>\n",
       "      <td>Ve</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>522</td>\n",
       "      <td>1784</td>\n",
       "      <td>35</td>\n",
       "      <td>58</td>\n",
       "      <td>35.542503</td>\n",
       "      <td>NIE</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>174</td>\n",
       "      <td>1797</td>\n",
       "      <td>75</td>\n",
       "      <td>84</td>\n",
       "      <td>57.116997</td>\n",
       "      <td>A</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>484</td>\n",
       "      <td>1836</td>\n",
       "      <td>224</td>\n",
       "      <td>69</td>\n",
       "      <td>40.947304</td>\n",
       "      <td>GEN</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>1152</td>\n",
       "      <td>2112</td>\n",
       "      <td>132</td>\n",
       "      <td>87</td>\n",
       "      <td>31.260712</td>\n",
       "      <td>BLL</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>932</td>\n",
       "      <td>2123</td>\n",
       "      <td>165</td>\n",
       "      <td>90</td>\n",
       "      <td>46.077896</td>\n",
       "      <td>een</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>526</td>\n",
       "      <td>2142</td>\n",
       "      <td>109</td>\n",
       "      <td>95</td>\n",
       "      <td>57.588829</td>\n",
       "      <td>a</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>662</td>\n",
       "      <td>2156</td>\n",
       "      <td>48</td>\n",
       "      <td>97</td>\n",
       "      <td>34.522789</td>\n",
       "      <td>ii</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    level  page_num  block_num  par_num  line_num  word_num  left   top  \\\n",
       "9       5         1          1        1         2         4  1400   344   \n",
       "11      5         1          1        1         3         1   175   435   \n",
       "12      5         1          1        1         3         2   215   435   \n",
       "15      5         1          1        1         3         5   336   435   \n",
       "17      5         1          1        1         3         7   413   448   \n",
       "23      5         1          1        1         5         1   164   783   \n",
       "30      5         1          1        1         6         5  1102   786   \n",
       "33      5         1          1        1         7         2  1350   883   \n",
       "26      5         1          1        1         6         1   128   913   \n",
       "37      5         1          1        1         8         3  1287  1537   \n",
       "41      5         1          1        1         9         3  1282  1546   \n",
       "40      5         1          1        1         9         2  1041  1557   \n",
       "46      5         1          1        1        10         4   932  1595   \n",
       "47      5         1          1        1        10         5  1040  1601   \n",
       "45      5         1          1        1        10         3   636  1618   \n",
       "48      5         1          1        1        10         6  1180  1619   \n",
       "55      5         1          1        1        11         5  1005  1686   \n",
       "52      5         1          1        1        11         2   270  1765   \n",
       "53      5         1          1        1        11         3   522  1784   \n",
       "51      5         1          1        1        11         1   174  1797   \n",
       "59      5         1          1        1        12         3   484  1836   \n",
       "67      5         1          1        1        13         6  1152  2112   \n",
       "66      5         1          1        1        13         5   932  2123   \n",
       "63      5         1          1        1        13         2   526  2142   \n",
       "64      5         1          1        1        13         3   662  2156   \n",
       "\n",
       "    width  height       conf text  row_id  col_id  \n",
       "9       2       2  41.559139    |       0      12  \n",
       "11     24      66  37.183258   el       1       0  \n",
       "12     28      66  52.886387   &)       1       0  \n",
       "15     22      66  36.425919   S|       1       2  \n",
       "17     13      20  36.664349    §       1       3  \n",
       "23    500     112  36.809917  TTT       2       0  \n",
       "30    151     116  40.074837  eee       2       8  \n",
       "33     22      61  33.002319   PR       3      11  \n",
       "26    162      24  40.332829   AH       4       0  \n",
       "37     82      31  32.156410   Ga       5      10  \n",
       "41     94      77  78.016541    @       5      10  \n",
       "40    163      72  35.844048   We       5       7  \n",
       "46     70      99  38.215660   Fe       6       6  \n",
       "47     32      71  53.231361  DAI       6       7  \n",
       "45    146      86  49.561317  LEP       6       5  \n",
       "48     24      24  42.241776   |B       6       9  \n",
       "55    229     137  42.315910   ae       7       7  \n",
       "52    120     120  36.928120   Ve       8       1  \n",
       "53     35      58  35.542503  NIE       8       4  \n",
       "51     75      84  57.116997    A       8       0  \n",
       "59    224      69  40.947304  GEN       9       4  \n",
       "67    132      87  31.260712  BLL      10       9  \n",
       "66    165      90  46.077896  een      10       6  \n",
       "63    109      95  57.588829    a      10       4  \n",
       "64     48      97  34.522789   ii      10       5  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df220c95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0172554d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import OCRToTableTool as ottt\n",
    "import TableExtractor as te\n",
    "import TableLinesRemover as tlr\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "af89742f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['page_1.jpg']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "os.listdir(\"Images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a8d878bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_image = \"Images/page_1.jpg\"\n",
    "table_extractor = te.TableExtractor(path_to_image)\n",
    "perspective_corrected_image = table_extractor.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1ddf942d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines_remover = tlr.TableLinesRemover(perspective_corrected_image)\n",
    "image_without_lines = lines_remover.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "593a8f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ocr_tool = ottt.OcrToTableTool(image_without_lines, perspective_corrected_image)\n",
    "ocr_tool.execute()\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d267e0",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "cv2.imshow(\"perspective_corrected_image\", perspective_corrected_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08265f27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Attendance_System",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
